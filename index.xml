<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Valentin Pelloin</title>
    <link>https://vpelloin.eu/</link>
    <description>Recent content on Valentin Pelloin</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 06 Sep 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://vpelloin.eu/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>:bullettrain_side: Interrail 2023: Denmark, Sweden, Germany, The Netherlands, Belgium</title>
      <link>https://vpelloin.eu/posts/interrail-2023/</link>
      <pubDate>Mon, 14 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://vpelloin.eu/posts/interrail-2023/</guid>
      <description>&lt;p&gt;This summer, I did my second Interrail trip. With an &lt;a href=&#34;https://www.interrail.eu/en&#34;&gt;Interrail&lt;/a&gt; pass, you can travel with many different trains throughout Europe with little to no additional cost. In this post, I will share some pictures I made during this trip through 5 different countries, as well as share the route and trains I have taken.&lt;/p&gt;
&lt;!-- My previous Interrail trip was described in [this post](/posts/interrail-2021). --&gt;</description>
    </item>
    
    <item>
      <title>Expose ta thÃ¨se 2022</title>
      <link>https://vpelloin.eu/links/expose_ta_these/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vpelloin.eu/links/expose_ta_these/</guid>
      <description>Expose ta thÃ¨se 2022 L&amp;rsquo;IA pour la comprÃ©hension de la parole Valentin PELLOIN Doctorant en 3e annÃ©e au LIUM (Laboratoire d&amp;rsquo;Informatique de l&amp;rsquo;UniversitÃ© du Mans). Encadrement : Nathalie Camelin, Antoine Laurent et Sylvain Meignier. Ã‰cole doctorale MaSTIC (anciennement MathSTIC). Formation : licence puis master Informatique. Contexte : projet ANR AISSPER (Artificial Intelligence for Semantically controlled SPEech UndeRstanding). Objectif : amÃ©lioration des systÃ¨mes de reconnaissance et de comprÃ©hension de la parole Ã  l&amp;rsquo;aide de mÃ©canismes d&amp;rsquo;attention et de modÃ¨les bout-en-bout (end to end).</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>https://vpelloin.eu/teaching/</link>
      <pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vpelloin.eu/teaching/</guid>
      <description>Teaching activities 2022-2023 Name Level Lectures Tutorials Labs Python introduction 1st year 14h 24h Database and SQL 2nd year 11h Complexity and data structures 3rd year 12h Natural Language Processing (NLP) 5th year 2h Total: 64h
2021-2022 Name Level Lectures Tutorials Labs Python introduction 1st year 14h 12h Database and SQL 2nd year 19h Database and SQL 4th year 3h Automata and transducers 4th year 2h 12h Total: 63h
2020-2021 Name Level Lectures Tutorials Labs Python introduction 1st year 24h Database and SQL 2nd year 36h Natural Language Processing (NLP) 5th year 1h Total: 61h</description>
    </item>
    
    <item>
      <title>:books: Notes: How does sequence generation works in Fairseq/Espresso?</title>
      <link>https://vpelloin.eu/posts/fairseq-sequence-generation/</link>
      <pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vpelloin.eu/posts/fairseq-sequence-generation/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/pytorch/fairseq&#34;&gt;Fairseq&lt;/a&gt; is a &amp;ldquo;sequence sequence modeling toolkit written in &lt;a href=&#34;http://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt; that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks&amp;rdquo;. I will try to explain how fairesq generates sequences with a Language Model while using a beam search algorithm.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>:books: Notes: Attention! Transformers!</title>
      <link>https://vpelloin.eu/posts/attention-transformers/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vpelloin.eu/posts/attention-transformers/</guid>
      <description>&lt;p&gt;Attention mechanisms, used in encoder-decoder reccurrent neural networks are able to align an input sequence to an output sequence.
The transformer, described in &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;Attention Is All You Need&lt;/a&gt;&amp;rdquo; is a network architecture capable of sequence-to-sequence translations, without using recurrence, and thus, allowing parallelization.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://vpelloin.eu/contact/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vpelloin.eu/contact/</guid>
      <description>Contact me Social networks bluesky/@vpelloin.eu mastodon.social/@valentinp72 github/valentinp72 linkedin/valentin-pelloin Scientifc networks google-scholar/51UZAZUAAAAJ orcid/0000-0002-1259-127X researchgate/valentin-pelloin-2 semanticscholar/1965962009 huggingface/vpelloin </description>
    </item>
    
    <item>
      <title>Gallery</title>
      <link>https://vpelloin.eu/gallery/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vpelloin.eu/gallery/</guid>
      <description>Gallery ðŸš„ Interrail 2023 pictures (ðŸ‡©ðŸ‡°,ðŸ‡¸ðŸ‡ª,ðŸ‡©ðŸ‡ª,ðŸ‡³ðŸ‡±,ðŸ‡§ðŸ‡ª) ðŸ”­ Astrophotography pictures ðŸ”­ Astrophotography pictures This gallery consists of (mainly) astrophotography pictures I made.
Jupiter (filmed)
Miky Way 1
Miky Way 2
full Moon 2
full Moon 3
full Moon
starry sky 1
starry sky 2
starry sky 3
starry sky 4
starry sky with tree
the Moon (filmed)
the Moon
All pictures in this gallery are licensed under CC BY-NC-SA 4.0. Attribution to Valentin Pelloin.</description>
    </item>
    
  </channel>
</rss>
